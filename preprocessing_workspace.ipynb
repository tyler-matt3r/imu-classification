{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing IMU Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Preprocessing IMU data before it goes into maneuver detection algorithms\"\"\"\n",
    "from typing import Dict, Union\n",
    "import numpy as np\n",
    "import simdkalman  # lightweight package, not currently a part of the docker\n",
    "from scipy.ndimage import uniform_filter1d\n",
    "import yaml\n",
    "\n",
    "\n",
    "# In KF, it is the ratio between the process noise and the observation noise\n",
    "# that matters\n",
    "KF_CONFIG = {\n",
    "    \"moving_window_size\": None,\n",
    "    \"kalman_process_noise\": 1.,\n",
    "    \"kalman_observation_noise\": 1.,\n",
    "    \"kalman_initial_covariance\": 10,\n",
    "}\n",
    "# sampling rate ~30Hz, and we want to see features of ~0.1 s long\n",
    "MOVING_AVERAGE_CONFIG = {\n",
    "    \"moving_window_size\": 4,\n",
    "    \"kalman_process_noise\": None,\n",
    "    \"kalman_observation_noise\": None,\n",
    "    \"kalman_initial_covariance\": None,\n",
    "}\n",
    "\n",
    "\n",
    "class IMUPreprocessor():\n",
    "    \"\"\"Preprocess IMU data before it goes into maneuver detection algorithms.\n",
    "\n",
    "    Roughly follows methods from M. Tabatabaei et al. \"Driver Maneuver\n",
    "    Identification Using Inertial Sensors and a Machine Learning Algorithm\"\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        moving_window_size: int = None,\n",
    "        kalman_process_noise: float = None,\n",
    "        kalman_observation_noise: float = None,\n",
    "        kalman_initial_covariance: float = None,\n",
    "    ):\n",
    "        # moving average filter\n",
    "        self.moving_window_size = moving_window_size\n",
    "        # kalman filter - see https://simdkalman.readthedocs.io/en/latest/\n",
    "        self.kalman_process_noise = kalman_process_noise\n",
    "        self.kalman_observation_noise = kalman_observation_noise\n",
    "        self.kalman_initial_covariance = kalman_initial_covariance\n",
    "\n",
    "        self._init_tools()\n",
    "\n",
    "    def _init_tools(self):\n",
    "        \"\"\"Initialize tools for preprocessing based on configuration\"\"\"\n",
    "\n",
    "        # Kalman parameters should both be either set or unset\n",
    "        if (\n",
    "            (self.kalman_observation_noise is None)\n",
    "            ^ (self.kalman_process_noise is None)\n",
    "        ):\n",
    "            raise ValueError(\"Kalman filter parameters incorrectly set\")\n",
    "\n",
    "        self.kalman_filter = (\n",
    "            simdkalman.KalmanFilter(\n",
    "                state_transition=[[1]],  # A\n",
    "                process_noise=self.kalman_process_noise,  # Q\n",
    "                observation_model=np.array([[1]]),  # H\n",
    "                observation_noise=self.kalman_observation_noise  # R\n",
    "            )\n",
    "            if self.kalman_process_noise is not None else None\n",
    "        )\n",
    "\n",
    "    def update_cfg(self, config: Union[str, dict]):\n",
    "        \"\"\"Update configuration from a file or dictionary\"\"\"\n",
    "        if isinstance(config, str):\n",
    "            with open(config, 'r') as f:\n",
    "                cfg = yaml.safe_load(f)\n",
    "        else:\n",
    "            cfg = config\n",
    "\n",
    "        for attr_name in [\n",
    "            \"moving_window_size\",\n",
    "            \"kalman_process_noise\",\n",
    "            \"kalman_observation_noise\",\n",
    "            \"kalman_initial_covariance\",\n",
    "        ]:\n",
    "            setattr(\n",
    "                self,\n",
    "                attr_name,\n",
    "                cfg[attr_name] if attr_name in cfg else None\n",
    "            )\n",
    "        self._init_tools()\n",
    "\n",
    "    def _is_imu_values_name(self, key: str) -> bool:\n",
    "        \"\"\"name of a column corresponds to either acceleration or gyro\"\"\"\n",
    "        return \"time\" not in key\n",
    "\n",
    "    def _moving_average(self, data: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Moving average filter for every key in data except timestamps\n",
    "\n",
    "        If the moving window size is not set, returns data unchanged.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            data : array of the dimension (n_sensors, n_time_points)\n",
    "            Returns\n",
    "        -------\n",
    "            array smooth values of the dimension (n_sensors, n_time_points)\n",
    "        \"\"\"\n",
    "        # This solution relies on scipy.ndimage. If that library becomes\n",
    "        # unavailable on k3y, look at\n",
    "        # https://stackoverflow.com/questions/13728392/moving-average-or-running-mean,\n",
    "        # mind edge efects\n",
    "        return (\n",
    "            uniform_filter1d(data, size=self.moving_window_size, axis=1)\n",
    "            if self.moving_window_size is not None else data\n",
    "        )\n",
    "\n",
    "    def _kalman_smoother(self, data):\n",
    "        \"\"\"Kalman filter with noise-only term\n",
    "\n",
    "        relies on https://simdkalman.readthedocs.io/en/latest/\n",
    "        \"\"\"\n",
    "        if self.kalman_filter is None:\n",
    "            return data\n",
    "\n",
    "        smoothed = self.kalman_filter.smooth(\n",
    "            data,\n",
    "            initial_value=[0],\n",
    "            initial_covariance=[[self.kalman_initial_covariance]]\n",
    "        ).states.mean\n",
    "\n",
    "        return np.squeeze(smoothed)\n",
    "\n",
    "    def _normalize(self, data: np.ndarray) -> np.ndarray:\n",
    "        # TODO: normalize to -1..1 min-max based on the training data\n",
    "        print(\"WARNING: normalization is not implemented yet\")\n",
    "        return data\n",
    "\n",
    "    def preprocess(self, data: Dict[str, np.ndarray]) -> Dict[str, np.ndarray]:\n",
    "        \"\"\"Run all preprocessing steps on the data\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "            data : dictionary of arrays, obtained by merging the acceleration\n",
    "                and gyro dataframes. Keys are the names of the columns\n",
    "        Returns:\n",
    "        --------\n",
    "            dictionary of arrays, with the keys same as the input except an\n",
    "            extra suffix\n",
    "        \"\"\"\n",
    "        # transform the input dictionary into an array for numerical efficiency\n",
    "        key_lookup = {}\n",
    "        data_stack = []\n",
    "        non_imu_keys = []\n",
    "\n",
    "        i = 0\n",
    "        for key, vals in data.items():\n",
    "            if self._is_imu_values_name(key):\n",
    "                key_lookup[i] = key\n",
    "                data_stack.append(vals)\n",
    "                i += 1\n",
    "            else:\n",
    "                non_imu_keys.append(key)\n",
    "        data_np = np.vstack(data_stack)\n",
    "\n",
    "        # apply preprocessing steps one by one\n",
    "        data_np = self._moving_average(data_np)\n",
    "        data_np = self._kalman_smoother(data_np)\n",
    "        data_np = self._normalize(data_np)\n",
    "\n",
    "        # split the result back into a dictionary\n",
    "        result = {key: data[key] for key in non_imu_keys}\n",
    "        for i, key in key_lookup.items():\n",
    "            result[key] = data_np[i, :]\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch some example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a = pd.read_parquet(\"data/accel_2023-07-10_22-00-00.parquet\")\n",
    "df_g = pd.read_parquet(\"data/gyro_2023-07-10_22-00-00.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
