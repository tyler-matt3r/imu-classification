{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyler/.local/lib/python3.10/site-packages/tslearn/bases/bases.py:15: UserWarning: h5py not installed, hdf5 features will not be supported.\n",
      "Install h5py to use hdf5 features: http://docs.h5py.org/\n",
      "  warn(h5py_msg)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.ndimage import uniform_filter1d, gaussian_filter1d\n",
    "from tslearn.utils import to_time_series_dataset\n",
    "from tslearn.neighbors import KNeighborsTimeSeriesClassifier, \\\n",
    "    KNeighborsTimeSeries\n",
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_directory = '/home/tyler/Documents/Matt3r/imu-classification/DATA/train_8s_stage3'\n",
    "validation_directory = '/home/tyler/Documents/Matt3r/imu-classification/DATA/val_8s_stage3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreprocessData:\n",
    "    ''' Load all data contained in the directory as X and Y.\n",
    "        Labels are stored in labels\n",
    "    '''\n",
    "    def __init__(self, directory):\n",
    "        self.X = []\n",
    "        self.Y = []\n",
    "        self.labels = []\n",
    "        for id, folder in enumerate(os.listdir(directory)):\n",
    "            self.labels.append(folder)\n",
    "            folder_list = []\n",
    "            for file_name in os.listdir(os.path.join(directory, folder)):\n",
    "                if file_name.endswith(\".pkl\"):\n",
    "                    file_path = os.path.join(directory, folder, file_name)\n",
    "                    with open(file_path, \"rb\") as file:\n",
    "                        data = pickle.load(file)\n",
    "                        folder_list.append(data['matt3r_format'])\n",
    "            self.X.append(folder_list)\n",
    "            self.Y.append([id] * len(folder_list))\n",
    "\n",
    "    ''' Smoothen and discretize the data to length 50.\n",
    "        If method = gaussian then perform a gaussian smoothing\n",
    "        If method = moving average then compute the moving average\n",
    "    '''\n",
    "    def smoothen_discretize(self, smoothing_method='gaussian'):\n",
    "        if smoothing_method == 'gaussian':\n",
    "            SIGMA = 2.5\n",
    "            FINAL_SEQ_LENGTH = 50\n",
    "            offset = (400 / FINAL_SEQ_LENGTH) / 2\n",
    "            DOWNSAMPLING_INDEXES = np.linspace(offset, 400-offset, FINAL_SEQ_LENGTH).round().astype(int)\n",
    "            for class_num in range(len(self.X)):\n",
    "                for id, timeseries in enumerate(self.X[class_num]):\n",
    "                    # convert to numpy\n",
    "                    data_np = np.vstack([timeseries[col] for col in timeseries])[1:,:]\n",
    "                    # smooth data\n",
    "                    data_smooth = gaussian_filter1d(data_np, sigma=SIGMA, mode='nearest')\n",
    "                    # downsample\n",
    "                    self.X[class_num][id] = data_smooth[:, DOWNSAMPLING_INDEXES]\n",
    "        elif smoothing_method == 'moving average':\n",
    "            WINDOW_SIZE = 6\n",
    "            DISC_STEP = 8\n",
    "            for class_num in range(len(self.X)):\n",
    "                for id, timeseries in enumerate(self.X[class_num]):\n",
    "                    for column in timeseries:\n",
    "                        sequence = timeseries[column]\n",
    "                        # compute moving average\n",
    "                        sequence = uniform_filter1d(sequence, size=WINDOW_SIZE)\n",
    "                        # discretize\n",
    "                        if DISC_STEP > 1:\n",
    "                            n = len(sequence)\n",
    "                            n_steps = int(np.ceil(n / DISC_STEP))\n",
    "                            sequence = np.array([\n",
    "                                sequence[ i * DISC_STEP:(i + 1) * DISC_STEP].mean() \n",
    "                                for i in range(n_steps)\n",
    "                            ])\n",
    "                        timeseries[column] = sequence\n",
    "                    # convert to numpy\n",
    "                    self.X[class_num][id] = np.vstack([timeseries[col] for col in timeseries])[1:,:]\n",
    "        else:\n",
    "            # perform no smoothing or discretization\n",
    "            for class_num in range(len(self.X)):\n",
    "                for id, timeseries in enumerate(self.X[class_num]):\n",
    "                    # convert to numpy\n",
    "                    self.X[class_num][id] = np.vstack([timeseries[col] for col in timeseries])[1:,:]\n",
    "\n",
    "    ''' Normalize the data.\n",
    "        If method = standardized then divide by the precomputed standard deviation.\n",
    "        If method = maxmin then perform max/min normalization between -1 and 1.\n",
    "        If no method is passed then no normalization will be done.\n",
    "    '''\n",
    "    def normalize(self, normalize_method='standardized'):\n",
    "        if normalize_method == 'maxmin':\n",
    "            # compute the max and min values per axis\n",
    "            mins = np.inf * np.ones(6)\n",
    "            maxs = -np.inf * np.ones(6)\n",
    "            for class_num in range(len(self.X)):\n",
    "                for data in self.X[class_num]:\n",
    "                    mins = np.min([mins, np.min(data, axis=1)], axis=0)\n",
    "                    maxs = np.max([maxs, np.max(data, axis=1)], axis=0)\n",
    "            # normalize to +/-1\n",
    "            ranges = maxs - mins\n",
    "            mins = mins[:, np.newaxis]\n",
    "            ranges = ranges[:, np.newaxis]\n",
    "            for class_num in range(len(self.X)):\n",
    "                for id, data in enumerate(self.X[class_num]):\n",
    "                    self.X[class_num][id] = ((data - mins) / ranges) * 2 - 1\n",
    "        elif normalize_method == 'standardized':\n",
    "            # precomputed standard deviations\n",
    "            STD_DEVS = np.array([[1.33343277], [1.59291318], [0.52805266], [0.07645243], [0.07536972], [0.22749133]])\n",
    "            for class_num in range(len(self.X)):\n",
    "                for id, data in enumerate(self.X[class_num]):\n",
    "                    self.X[class_num][id] = data / STD_DEVS\n",
    "\n",
    "    ''' Compute the cumulative sum of each time series.\n",
    "        The axis field allows you to pass a list of which IMU fields you would like to integrate.\n",
    "        0 = lr_acc, 1 = bf_acc, 2 = vert_acc, 3 = lr_gyro, 4 = bf_gyro, 5 = vert_gyro\n",
    "        dt is the length of time for each sample in seconds\n",
    "        N is the length of each time series sample\n",
    "    '''\n",
    "    def integrate(self, axes=[0,5], dt=8, N=50):\n",
    "        for class_num in range(len(self.X)):\n",
    "                for id, data in enumerate(self.X[class_num]):\n",
    "                    for axis in axes:\n",
    "                        self.X[class_num][id] = dt * np.cumsum(data) / N\n",
    "\n",
    "    ''' Perform all of the preprocessing steps in a single function call.\n",
    "        Pass in the arguments for the necessary preprocessing steps you wish to perform.\n",
    "    '''\n",
    "    def preprocess(self, **kwargs):\n",
    "        # smoothen and discretize\n",
    "        if 'smoothing_method' in kwargs:\n",
    "            self.smoothen_discretize(kwargs['smoothing_method'])\n",
    "        else: self.smoothen_discretize()\n",
    "        # normalize\n",
    "        if 'normalize_method' in kwargs:\n",
    "            self.normalize(kwargs['normalize_method'])\n",
    "        else: self.normalize()\n",
    "\n",
    "    ''' Converts the data from each class to a timeseries object with a set number of samples.\n",
    "        The axis field allows you to pass a list of which IMU fields you would like to include.\n",
    "        0 = lr_acc, 1 = bf_acc, 2 = vert_acc, 3 = lr_gyro, 4 = bf_gyro, 5 = vert_gyro\n",
    "    '''\n",
    "    def to_timeseries(self, num_samples, axes=[0,5]):\n",
    "        for class_num in range(len(self.X)):\n",
    "            # shuffle data for each instance\n",
    "            indices = list(range(len(self.X[class_num])))\n",
    "            random.shuffle(indices)\n",
    "            self.X[class_num] = to_time_series_dataset([self.X[class_num][i][axes,:].T for i in indices][:num_samples])\n",
    "            self.Y[class_num] = self.Y[class_num][:num_samples]\n",
    "\n",
    "    ''' Cluster the data for each class into a set number of clusters.\n",
    "    '''\n",
    "    def cluster(self, num_clusters, cluster_method='dtw', **kwargs):\n",
    "        for class_num in range(len(self.X)):\n",
    "            km = TimeSeriesKMeans(num_clusters, metric=cluster_method, **kwargs)\n",
    "            km.fit(self.X[class_num])\n",
    "            self.X[class_num] = km.cluster_centers_\n",
    "\n",
    "    ''' Returns the timeseries data, X, and the corresponding labels, Y\n",
    "        X: ndarray of shape (num_samples, len_time_series, num_dimensions)\n",
    "        Y: ndarray of shape (num_samples) containing int values corresponding to the class\n",
    "    '''\n",
    "    def get_arrays(self):\n",
    "        X_ts = np.concatenate(self.X, axis=0)\n",
    "        Y_ts = np.concatenate(self.Y)\n",
    "        return X_ts, Y_ts\n",
    "\n",
    "    ''' Produces a KNN model that can be used to predict maneuvers.\n",
    "    '''\n",
    "    def produce_knn(self, k=1, distance_metric='dtw', **kwargs):\n",
    "        knn_clf = KNeighborsTimeSeriesClassifier(n_neighbors=k, metric=distance_metric, **kwargs)\n",
    "        knn_clf.fit(self.X, self.Y)\n",
    "        return knn_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainingData = PreprocessData(training_directory)\n",
    "TrainingData.smoothen_discretize('gaussian')\n",
    "# TrainingData.normalize('standardized')\n",
    "# TrainingData.preprocess()\n",
    "TrainingData.to_timeseries(100)\n",
    "X, Y = TrainingData.produce_knn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 50, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.36389335e-02,  1.30353234e-01, -1.82329873e-02,\n",
       "        -2.62918848e-01, -4.26173395e-01, -4.76318001e-01,\n",
       "        -7.76477039e-01, -9.36673138e-01, -7.17018226e-01,\n",
       "        -5.98285387e-01, -5.87059265e-01, -4.76407980e-01,\n",
       "        -3.84835215e-01, -4.04347984e-01, -2.58613583e-01,\n",
       "        -1.39456814e-01, -3.23120733e-02,  7.71416120e-02,\n",
       "         2.08742472e-02,  1.74646679e-02, -1.06795535e-02,\n",
       "         1.20084438e-01,  1.34140183e-01,  1.87118399e-01,\n",
       "         1.39884323e-01,  6.35695687e-02,  6.19733510e-02,\n",
       "         5.76316952e-02, -1.06442210e-01, -1.84797089e-01,\n",
       "        -4.06173067e-01, -3.37861429e-01, -1.48409476e-01,\n",
       "        -9.46714928e-03, -1.26102302e-01, -1.16813296e-01,\n",
       "         3.91221269e-03,  1.01776182e-01,  3.46962461e-02,\n",
       "         6.27627627e-02,  8.71126200e-02, -7.82807616e-02,\n",
       "        -3.52202702e-01, -2.31563640e-01, -8.98409020e-02,\n",
       "        -1.45740244e-02,  3.06453594e-02,  1.27606884e-01,\n",
       "         1.47813624e-01,  4.22987623e-01],\n",
       "       [ 5.81669511e-01,  3.99254496e-01,  3.58554689e-01,\n",
       "         4.31859302e-01,  5.79757835e-01,  5.56417036e-01,\n",
       "         4.68033232e-01,  4.81294730e-01,  5.70031759e-01,\n",
       "         3.95951865e-01,  4.10502517e-01,  5.79327743e-01,\n",
       "         6.58427479e-01,  3.33640112e-01,  3.69791048e-01,\n",
       "         3.44098473e-01,  1.94766510e-01,  2.43036867e-01,\n",
       "         1.23271006e-01,  2.35589681e-01,  2.04558060e-01,\n",
       "         1.76893845e-01,  2.49374412e-01,  1.95748889e-01,\n",
       "         4.53383842e-03, -9.45591113e-02,  2.35046646e-02,\n",
       "         2.16617353e-01, -7.53920833e-02,  1.57792674e-01,\n",
       "         2.93158847e-01,  1.99643813e-01,  3.24996844e-01,\n",
       "         2.22648150e-01,  1.29024440e-01,  4.39740252e-01,\n",
       "         2.73861781e-01,  3.21611673e-01,  6.73189306e-02,\n",
       "         2.66672056e-01,  2.92609150e-01,  1.48222303e-01,\n",
       "         5.53198642e-01,  5.68607083e-01,  1.14654930e+00,\n",
       "         1.63942271e+00,  1.89476099e+00,  2.71905270e+00,\n",
       "         2.93625897e+00,  3.74177666e+00],\n",
       "       [ 6.86897625e-02, -1.08505857e-01, -2.18776528e-01,\n",
       "        -1.22493061e-02,  4.71456474e-02,  1.84498919e-01,\n",
       "         1.14815724e-03, -1.50432994e-01, -1.19880044e-02,\n",
       "         1.63533130e-02, -1.54641183e-01, -1.93120617e-01,\n",
       "        -2.01631465e-01, -1.53572501e-01, -1.72933652e-01,\n",
       "        -1.31989350e-01, -8.11496231e-03,  7.11516304e-02,\n",
       "        -4.98692692e-02, -1.05302326e-01, -2.04236714e-01,\n",
       "        -2.04864394e-01, -5.18400094e-02, -6.28118787e-02,\n",
       "         1.79038057e-01,  1.38263030e-01, -7.01114859e-02,\n",
       "        -9.16348034e-02,  2.85405219e-02, -8.98430497e-02,\n",
       "         2.42893050e-01,  9.01745130e-02,  2.06181036e-02,\n",
       "        -1.38870543e-01, -3.67064017e-01,  1.52346389e-01,\n",
       "         4.77832782e-01, -1.35145215e-01, -2.61911291e-01,\n",
       "        -1.17191183e-01,  2.73526142e-01,  1.74177863e-01,\n",
       "        -8.32143548e-02, -8.82316930e-02, -2.16243431e-01,\n",
       "        -1.10452671e-01, -1.87389835e-01, -1.43096334e-01,\n",
       "        -1.64248471e-01, -2.61903216e-01],\n",
       "       [-1.51454773e-02, -9.63425538e-03,  5.11201959e-03,\n",
       "        -1.55825945e-02, -9.16361864e-03, -1.41443938e-02,\n",
       "        -9.99199437e-03,  4.24927478e-03, -1.25698852e-02,\n",
       "        -1.37828881e-02,  5.11587077e-03,  9.02673928e-03,\n",
       "         2.32502156e-03,  2.72689594e-03,  3.17777970e-03,\n",
       "        -1.09145707e-03, -1.02478021e-02, -7.23502158e-03,\n",
       "        -1.15050146e-02, -4.89850237e-03, -4.38140556e-03,\n",
       "         6.41436225e-03, -4.16493973e-03, -1.03007112e-02,\n",
       "        -5.37068049e-03, -2.48103992e-02, -7.25880852e-03,\n",
       "        -5.33303105e-03, -5.47829450e-03,  3.29567630e-03,\n",
       "        -9.73440581e-03, -2.10685736e-02,  7.23023000e-03,\n",
       "        -2.08154593e-02,  2.36404992e-02, -5.64910362e-03,\n",
       "        -1.93126522e-02, -4.23890253e-03, -7.14112173e-03,\n",
       "         1.45691218e-03, -1.36797277e-02, -2.23454156e-02,\n",
       "        -2.28222813e-03, -4.95852582e-03,  5.91561987e-03,\n",
       "        -1.69274336e-03, -7.07001811e-04, -4.81003256e-03,\n",
       "        -3.53391546e-03,  7.89481085e-04],\n",
       "       [-1.22823932e-02, -7.98430060e-03,  2.04273243e-04,\n",
       "         9.52862823e-03,  8.42271787e-03,  2.27523137e-02,\n",
       "         1.45927892e-02, -1.59976708e-02, -3.32569799e-02,\n",
       "        -2.56488916e-02, -2.24017769e-02, -1.20094619e-02,\n",
       "        -9.14261069e-03, -6.29359511e-03, -7.44290284e-03,\n",
       "        -4.20385935e-03,  1.48749666e-03,  4.69322286e-03,\n",
       "         4.68810744e-04, -3.33439140e-03, -1.37535937e-02,\n",
       "        -1.14428612e-02, -1.13359648e-02,  3.04843858e-03,\n",
       "         1.25220668e-02,  8.59907375e-03,  4.77691099e-03,\n",
       "         4.51640323e-03,  6.95700232e-03,  5.54526713e-03,\n",
       "        -8.15473055e-03, -2.69768187e-02, -2.30625606e-02,\n",
       "         6.02602582e-03,  8.87348917e-03, -1.37677262e-03,\n",
       "        -1.41164517e-02,  5.59565973e-03,  7.41351160e-03,\n",
       "        -6.78564870e-03, -1.76752407e-03,  6.12331135e-03,\n",
       "        -2.71362921e-03, -1.21021347e-02, -1.00490286e-02,\n",
       "         2.01518452e-03, -3.72574741e-03, -8.46919079e-03,\n",
       "        -7.36680242e-03, -1.54622968e-02],\n",
       "       [-2.30831099e-02, -3.07091165e-02, -3.88885722e-02,\n",
       "        -4.43786727e-02, -5.79675885e-02, -6.17619757e-02,\n",
       "        -7.28971491e-02, -7.27636019e-02, -6.54628592e-02,\n",
       "        -6.95839188e-02, -7.45678303e-02, -6.56201191e-02,\n",
       "        -6.75321589e-02, -6.25287032e-02, -5.77504826e-02,\n",
       "        -4.89770759e-02, -4.11429023e-02, -3.43378355e-02,\n",
       "        -3.27012173e-02, -3.08766526e-02, -2.99978713e-02,\n",
       "        -2.55302294e-02, -2.78813386e-02, -2.91510889e-02,\n",
       "        -2.67960286e-02, -2.74784610e-02, -2.69565759e-02,\n",
       "        -2.95104568e-02, -3.34555109e-02, -3.53280428e-02,\n",
       "        -3.70759491e-02, -4.18702629e-02, -4.22874150e-02,\n",
       "        -5.05834828e-02, -4.74384443e-02, -2.31818975e-02,\n",
       "        -2.43666652e-02, -3.03270886e-02, -2.22880960e-02,\n",
       "        -2.21018399e-02, -2.19004460e-02, -3.49927071e-02,\n",
       "        -3.98485158e-02, -3.36314591e-02, -3.70195213e-02,\n",
       "        -3.31974317e-02, -3.10743277e-02, -1.80568037e-02,\n",
       "        -1.77978507e-02, -1.69002750e-02]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainingData.X[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
